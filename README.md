# INT_DETECT

To Reviewer #1:

1. Our design heavily relies on protocol-independent forwarding devices, i.e., Tofino (P4 hardware switch) or Bmv2 (P4 software switch) at present. However, Tofino is expensive and quite inaccessible currently, we have to conduct emulation with Bmv2 on a physical x86 server with E5-2603v4 CPU @ 1.7GHz and 6 cores. In our experiment, we find that the performance of Bmv2 is quite limited and CPU-intensive. As a result, a large-scale topology and a high-speed packet sending rate to mimic real-world DCN will take up too much CPU resource. After analyzing the performance capability of the testbed, we choose a data center topology snippet with 8 switches and 8 servers (the same topology in HULA paperï¼‰. Considering the page limit, we do omit some details in evaluation: The input traffic is randomly generated from end servers with packet forwarding paths governed by random source routing tags. On each server, we allocated 20 python packet generators, contributing to 8Mbps packet throughput. The measurement duration in Fig. 7 is 5 minutes and the number of runs is 3 times. The number of runs for Fig. 9 is 100 times.

2. Limited by space, the INT implementation details are ommited. We upload the source files at https://github.com/graytower/INT_DETECT for your reference. The P4 source file is INT_DETECT/p4_source_code/my_int.p4. There are two key points of INT implementation: First, we parse the SR headers (line 79-85) and assign the first SR value to standard_metadata.egress_spec (line 120-123), making the packet forwarded through the port we specify. Second, we collect INT information from standard_metadata (line 170-177), and add the INT header to the INT probe (line 242). As far as we know, the P4 language is target-independent. The features of Bmv2 we use (like changing the value or reading the value from standard_metadate, removing or adding a header) are also compatible in Tofino (perhaps the name of standard_metadata is different), so there should be no challenge to deploy our design on a hardware target.

3. The most significant difference between gray failure and network congestion is that the gray failure will last for a much longer time than the congestion. When congestion occurs, the end host will soon decrease the amount of sending traffic. For distinguishing them, the aging time set for each path should be a bit longer for filtering the normal congestion out from the gray failure. In our design, the gray failure detection is done at the server side by the server or the smartNIC attached to the server. Only the identified gray failure will trigger fast traffic reroute and be alarmed to the controller. If there are some severe congestions lasting for a long time (e.g., 10s), our system will also (mis)identify them as gray failures and start fast traffic reroute, but we think this reaction is appropriate because the affected paths choke heavily.  (In our paper, we do not emphasize the above points and we will add them into the final version if chances are given)

4. Exactly, we preassume that all links are symmetric. Therefore, our current design can not deal with the gray failure occuring in asymmetric links. One of the solutions we think of after reading reviewer's comments is that each probe packet should record the path it comes through with source routing, and then go back through this path after reaching the last hop. In this way, the asymmetric link can be detected by both directions.

5. In our design, the detection mechanism is put to the end. It can be implemented on server OS or SmartNIC attached to server. As far as we know, more and more network functionalities at the end are offloaded onto SmartNIC for performance acceleration and leave more processing power to the servers. The SmartNIC can achieve very high speed (e.g., 100Gbps forwarding throughput). Therefore, we have confidence that our approach will work without performance burden in real data center networks.

Answer to additional points:
(1)  The probing method in our design is exactly the same with that in HULA. The purpose of our design and that of HULA is totally different. Our aim is failure detection while HULA is designed for load balancing. That is why we have not compared much about these two mechanisms. However, this advice is still constructive, we consider to compare our design with other approaches like NetBouncer, Pingmesh, etc.

(2) The current solution aims at detecting single gray failures. As for mult failures, we currently have not worked out an accurate and efficient algorithm to locate the failures. We will do further research into this direction. Thanks!

(3) The figure about traffic reroute (Fig. 8) records the change of traffic during 1100s, making it difficult to see the exact change of the relevent period between the actual failure. We will use a more microscopic figure to show the traffic reroute. For example, if the failure occurs in 500s, the figure will show the traffic from 450s to 550s instead of from 0s to 1100s.

(4) We will read the two papers proposed by reviewer and cite them if appropriate.

To Reviewer #2:

1.  In NetBouncer, the probing plan is to send probe packets with the IP-in-IP technique to detect the specified paths. And the probe packets will be bounced by the last switch in its path, that is, the probe packet will return through the origin path and be received by the sender. There are two keys points in the link failure localization algorithm:
(1) Several servers are required to send the probe packets (the servers and the paths are all specified by a controller). These servers are also called observers, which will calculate the rate (as Y0) between the number of probe packets sent and that of probe packets received. For example, if 100 probe packets are sent and only 49 of them are received, the total packet loss rate will be 51/100. 
(2) Assume that all the links are independent, and each of them has an assumed packet loss rate, range from 0 to 100%. In each path, use the packet loss rate to estimate the total packet loss rate the the path (as Y). By adjusting the assumed packet loss rate of each link to minimize the difference between Y and Y0. And analyze the packet loss rate of each link to determine which link is failed (whose packet loss rate is larger than a threshold).

2. There might be two scenarios that probe packet is going to corrupt: 
First, when some links suffer congestion, which might causes some servers to mistakely treat them as network failures. However, in our design, a bit longer aging time (e.g., 1s) of each path can largely alleviate this problem. The path will be aged only if no probe packet about it arrived within the aging time. So a relatively long aging time can filter out some light congestion (because light congestion will not last too long due to the fast decrease of the transmit window size at the end). While paths still might be aged due to severe congestion, which we think can be treats as a network failure and traffic reroute is quite appropriate. So this scenarios has little effect on network failure localization and rerouting. Second, probe packets collect some wrong data or it is changed unexcepted during transmisstion. In practise, there are often some error correction mechanisms in hardware and the process of transmission, so it should happen rarely.

3. The aging mechanism ensures that all the paths are feasible. Therefore, when some paths are down, the traffic on these paths should be rerouted to the feasible paths. At the same time, some load balancing technique (e.g., ECMP) can be used to assign these traffic to different paths, or send these data with a intervals, ensuring it will not put a high burden on other paths in a short time slice. 

To Reviewer #3:

1. Our probing plan is designed for Fat-Tree topology specifically. The probe packets will not get into any circles in this particular kind of topology. But for more general topologies, we need to carefully plan the broadcasting/multicasting methodology at each ports to avoid packet loop which is beyond the scope of this paper.

2. Round-Robin method is used in our design. In the experiment, all the end hosts are run in one physical server, meaning all of them share the same clock. So it is easy to make clock synchronization in each server, and they will consecutively send probe packets when sleep for a certain time. But in real-world distributed system, one or more controllers should be used to conduct clock synchronization.


3. Admittedly, we neglected to do some comparison between our design and other machinism such as Pingmesh and NetBouncer. We will make more efforts to study the differecnt of performance among them. 


4. The most significant difference between gray failure and network congestion is that the gray failure will last for a much longer time than the congestion. When congestion occurs, the end host will soon decrease the amount of sending traffic. For distinguishing them, the aging time set for each path should be a bit longer for filtering the normal congestion out from the gray failure. In our design, the gray failure detection is done at the server side by the server or the smartNIC attached to the server. The normal congestion will be filtered by the time-out mechanism and will not cause fluctuations. Only the identified gray failure will trigger fast traffic reroute and be alarmed to the controller. If there are some severe congestions lasting for a long time (e.g., 10s), our system will also (mis)identify them as gray failures and start fast traffic reroute, but we think this reaction is appropriate because the affected paths choke heavily.  (In our paper, we do not emphasize the above points and we will add them into the final version if chances are given)
